# Statistical Learning

## Description
This is an introductory-level course in supervised learning, with a focus on regression and classification methods. The syllabus includes: linear and polynomial regression, logistic regression and linear discriminant analysis; cross-validation and the bootstrap, model selection and regularization methods (ridge and lasso); nonlinear models, splines and generalized additive models; tree-based methods, random forests and boosting; support-vector machines. Some unsupervised learning methods are discussed: principal components and clustering (k-means and hierarchical).

This is not a math-heavy class, so we try and describe the methods without heavy reliance on formulas and complex mathematics. We focus on what we consider to be the important elements of modern data analysis. Computing is done in R. There are lectures devoted to R, giving tutorials from the ground up, and progressing with more detailed sessions that implement the techniques in each chapter.

Information : [Statistical Learning (Self-Paced)](https://online.stanford.edu/courses/sohs-ystatslearning-statistical-learning-self-paced)

Platform : [RStudio](http://www.rstudio.com/) 

Github: [StatLearning](https://github.com/ttungl/Statistical-Learning)

## Syllabus
| Lession |  |
| --- | --- |
| Ch1 Introduction |  |
| Ch2 Overview of Statistical Learning | |
| Ch3 Linear Regression |   |
| Ch4 Classification |  |
| Ch5 Resampling Methods | |
| Ch6 Linear Model Selection and Regularization | |
| Ch7 Moving Beyond Linearity | |
| Ch8 Tree-Based Methods | |
| Ch9 Support Vector Machines | |
| Ch10 Unsupervised Learning | |


## Reference Courses/Books
[An Introduction to Statistical Learning, with Applications in R by James, Witten, Hastie and Tibshirani (Springer, 2013)](http://www-bcf.usc.edu/~gareth/ISL/)

The Elements of Statistical Learning: Data Mining, Inference, and Prediction. Second Edition.




